{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter all data\n",
    "This takes the raw results for both experiments and removes the following:\n",
    "* Empty columns\n",
    "* Privac sensitive columns\n",
    "* Rejected workers\n",
    "* Contradicting answers that were not rejected workers\n",
    "* Workers that did the first experiment twice\n",
    "* Iphone and android users\n",
    "* Time spent on scenarios must be > 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp1_f1232791.csv\n",
      "Columns: 62\n",
      "Columns: 37 Empty\n",
      "Rows: 200\n",
      "Rows: 178 Rejected\n",
      "Rows: 178 Contradicting\n",
      "Rows: 178 Doubles\n",
      "Rows: 176 iPhone\n",
      "Rows: 176 Android\n",
      "Rows: 175 time\n",
      "Columns: 38 Privacy\n",
      "Rows: 175 time\n",
      "exp1_f1233325.csv\n",
      "Columns: 64\n",
      "Columns: 38 Empty\n",
      "Rows: 725\n",
      "Rows: 613 Rejected\n",
      "Rows: 610 Contradicting\n",
      "Rows: 471 Doubles\n",
      "Rows: 470 iPhone\n",
      "Rows: 462 Android\n",
      "Rows: 449 time\n",
      "Columns: 38 Privacy\n",
      "Rows: 449 time\n",
      "exp2_f1233802.csv\n",
      "Columns: 74\n",
      "Columns: 43 Empty\n",
      "Rows: 628\n",
      "Rows: 535 Rejected\n",
      "Rows: 535 Contradicting\n",
      "Rows: 535 Doubles\n",
      "Rows: 533 iPhone\n",
      "Rows: 522 Android\n",
      "Rows: 501 time\n",
      "Columns: 43 Privacy\n",
      "Rows: 501 time\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "inputFolder = folder+\"/Data/1.raw/\"\n",
    "outputFolder = folder+\"/Data/2.filtered/\"\n",
    "\n",
    "for f in os.listdir(inputFolder):\n",
    "    # ignore non csv files\n",
    "    if not f.endswith('csv'):\n",
    "        continue\n",
    "    print f\n",
    "    \n",
    "    # load data\n",
    "    df = pd.read_csv(inputFolder+f)\n",
    "            \n",
    "    # remove empty columns\n",
    "    print 'Columns:',df.shape[1]\n",
    "    df.dropna(axis=1, how='all', inplace=True)\n",
    "    print 'Columns:',df.shape[1],\"Empty\"\n",
    "    \n",
    "    \n",
    "    # remove rejected workers\n",
    "    print 'Rows:',df.shape[0]\n",
    "    df = df[df['_tainted'] == False]\n",
    "    print 'Rows:',df.shape[0],\"Rejected\"\n",
    "    \n",
    "    # remove contradicting answers that were not rejected workers\n",
    "    if 'spam' not in df.columns:\n",
    "        df['spam'] = 0\n",
    "    df = df[df['spam'] == 0]\n",
    "    print 'Rows:',df.shape[0],\"Contradicting\"\n",
    "    \n",
    "    # remove workers that did the first experiment twice\n",
    "    # take their first answer as the true data\n",
    "    if f == 'exp1_f1232791.csv':\n",
    "        workers = df['_worker_id']\n",
    "    if f == 'exp1_f1233325.csv':\n",
    "        df = df[~df['_worker_id'].isin(workers)]\n",
    "    print 'Rows:',df.shape[0],\"Doubles\"\n",
    "    \n",
    "    # remove iphone and android users\n",
    "    df = df[df.apply(lambda row: 'iPhone' not in row['browser'], axis=1)]\n",
    "    print 'Rows:',df.shape[0],\"iPhone\"\n",
    "    df = df[df.apply(lambda row: 'Android' not in row['browser'], axis=1)]\n",
    "    print 'Rows:',df.shape[0],\"Android\"\n",
    "    \n",
    "    # remove if time is not > 2\n",
    "    if 'time_none' in df.columns:\n",
    "        df = df[df['time_none'] > 2]\n",
    "        df = df[df['time_warning'] > 2]\n",
    "        df = df[df['time_danger'] > 2]\n",
    "    else:\n",
    "        df = df[df['time_suggestion'] > 2]\n",
    "        df = df[df['time_hours'] > 2]\n",
    "        df = df[df['time_numerical'] > 2]\n",
    "    print 'Rows:',df.shape[0],\"time\"\n",
    "    \n",
    "    \n",
    "    # overwrite privacy sensitive columns\n",
    "    df['_ip'] = 0\n",
    "    df['browser'] = 0\n",
    "    df['_city'] = 0\n",
    "    df['_region'] = 0\n",
    "    df['naam'] = 0\n",
    "    print 'Columns:',df.shape[1],\"Privacy\"\n",
    "        \n",
    "    print 'Rows:',df.shape[0],\"time\"\n",
    "    \n",
    "    df.to_csv(outputFolder+f, index=False)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined results of both experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import crowdtruth\n",
    "\n",
    "\n",
    "class config():\n",
    "    inputColumns = ['a']\n",
    "    outputColumns = [\n",
    "       'experiment1','experiment2',\n",
    "       'alert_suggestion', 'alert_numerical',\n",
    "       'feeling_danger', 'feeling_hours',\n",
    "       'feeling_none', 'feeling_numerical',\n",
    "       'feeling_suggestion', 'feeling_warning',\n",
    "       'imageorder', 'income', 'indebt',\n",
    "       'nobuyreason',\n",
    "       'product', 'regret', 's_danger',\n",
    "       's_hours', 's_none', 's_numerical',\n",
    "       's_suggestion', 's_warning',\n",
    "       'time_danger', 'time_hours', 'time_none',\n",
    "       'time_numerical', 'time_pre', 'time_suggestion',\n",
    "       'time_warning', 'warnings']\n",
    "\n",
    "    # processing of a closed task\n",
    "    open_ended_task = False\n",
    "    annotation_vector = []#['s_none','s_warning','s_danger']\n",
    "\n",
    "    def processJudgments(self, judgments):\n",
    "        if 's_none' not in judgments.columns:\n",
    "            judgments['experiment1'] = 0\n",
    "            judgments['experiment2'] = 1\n",
    "            \n",
    "            judgments['s_suggestion'] = judgments['s_suggestion'].map(lambda x: str(x)[:-1])\n",
    "            judgments['s_hours'] = judgments['s_hours'].map(lambda x: str(x)[:-1])\n",
    "            judgments['s_numerical'] = judgments['s_numerical'].map(lambda x: str(x)[:-1])\n",
    "\n",
    "            judgments['time_suggestion'] = judgments['time_suggestion'].astype('int')\n",
    "            judgments['time_hours'] = judgments['time_hours'].astype('int')\n",
    "            judgments['time_numerical'] = judgments['time_numerical'].astype('int')\n",
    "            \n",
    "            judgments['s_none'] = 0\n",
    "            judgments['s_warning'] = 0\n",
    "            judgments['s_danger'] = 0\n",
    "            \n",
    "            judgments['time_none'] = 0\n",
    "            judgments['time_warning'] = 0\n",
    "            judgments['time_danger'] = 0\n",
    "            \n",
    "            judgments['feeling_none'] = 0\n",
    "            judgments['feeling_warning'] = 0\n",
    "            judgments['feeling_danger'] = 0\n",
    "            \n",
    "        else :\n",
    "            judgments['experiment1'] = 1\n",
    "            judgments['experiment2'] = 0\n",
    "            judgments['alert_suggestion'] = -1\n",
    "            judgments['alert_numerical'] = -1\n",
    "            \n",
    "            judgments['s_none'] = judgments['s_none'].map(lambda x: str(x)[:-1])\n",
    "            judgments['s_warning'] = judgments['s_warning'].map(lambda x: str(x)[:-1])\n",
    "            judgments['s_danger'] = judgments['s_danger'].map(lambda x: str(x)[:-1])\n",
    "\n",
    "            \n",
    "            judgments['time_none'] = judgments['time_none'].astype('int')\n",
    "            judgments['time_warning'] = judgments['time_warning'].astype('int')\n",
    "            judgments['time_danger'] = judgments['time_danger'].astype('int')\n",
    "            \n",
    "            judgments['s_suggestion'] = 0\n",
    "            judgments['s_hours'] = 0\n",
    "            judgments['s_numerical'] = 0\n",
    "            \n",
    "            judgments['time_suggestion'] = 0\n",
    "            judgments['time_hours'] = 0\n",
    "            judgments['time_numerical'] = 0\n",
    "            \n",
    "            judgments['feeling_suggestion'] = 0\n",
    "            judgments['feeling_hours'] = 0\n",
    "            judgments['feeling_numerical'] = 0\n",
    "\n",
    "        \n",
    "        judgments['spam'] = '0'\n",
    "        #judgments['time_pre'] = judgments['time_pre'].astype('int')\n",
    "        #judgments.fillna(0, inplace=True)\n",
    "        #print judgments.head()\n",
    "        return judgments\n",
    "    \n",
    "data, config = crowdtruth.load(\n",
    "    directory = \"/Users/benjamin/Box Sync/TFI Research/Data/2.filtered/\",\n",
    "    config = config()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for p in config.output:\n",
    "    #print p\n",
    "    #print data['judgments']['output.'+p]\n",
    "    data['judgments']['output.'+p] = data['judgments']['output.'+p].apply(lambda x: ','.join(x))\n",
    "#print data['judgments'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# aggregate post questions\n",
    "posts = {\n",
    "    'income' : 'income',\n",
    "    'nobuyreason' : 'nobuyreason',\n",
    "    'timing_suggestion' : 'alert_suggestion',\n",
    "    'timing_numerical' : 'alert_numerical',\n",
    "    'warnings' : 'warnings',\n",
    "    'affordcheck' : 'indebt',\n",
    "    'payontime' : 'regret'\n",
    "}\n",
    "\n",
    "data['judgments']['output.experiment1'] = data['judgments']['output.experiment1'].astype('int')\n",
    "data['judgments']['output.experiment2'] = data['judgments']['output.experiment2'].astype('int')\n",
    "\n",
    "\n",
    "for p in posts:\n",
    "    data[p] = data['judgments'].copy()\n",
    "    data[p] = data[p][['output.'+posts[p],'output.experiment1','output.experiment2','output.s_none','output.s_warning','output.s_danger','output.s_suggestion','output.s_hours','output.s_numerical']]\n",
    "    data[p].columns = [p,'experiment1','experiment2','none','warning','danger','suggestion','hours','numerical']\n",
    "\n",
    "\n",
    "    data[p]['none'] = data[p]['none'].apply(lambda x: 1 if x == 'submit' else 0)\n",
    "    data[p]['warning'] = data[p]['warning'].apply(lambda x: 1 if x == 'submit' else 0)\n",
    "    data[p]['danger'] = data[p]['danger'].apply(lambda x: 1 if x == 'submit' else 0)\n",
    "    data[p]['suggestion'] = data[p]['suggestion'].apply(lambda x: 1 if x == 'submit' else 0)\n",
    "    data[p]['hours'] = data[p]['hours'].apply(lambda x: 1 if x == 'submit' else 0)\n",
    "    data[p]['numerical'] = data[p]['numerical'].apply(lambda x: 1 if x == 'submit' else 0)\n",
    "    \n",
    "    agg = {\n",
    "        p : 'count',\n",
    "        'experiment1' : 'sum',\n",
    "        'experiment2' : 'sum',\n",
    "        'none' : 'sum',\n",
    "        'warning' : 'sum',\n",
    "        'danger' : 'sum',\n",
    "        'suggestion' : 'sum',\n",
    "        'hours' : 'sum',\n",
    "        'numerical' : 'sum',\n",
    "    }\n",
    "    data[p] = data[p].groupby(p).agg(agg)\n",
    "    data[p]['none'] = data[p].apply(lambda row: row['none'] / float(row['experiment1']), axis = 1)\n",
    "    data[p]['warning'] = data[p].apply(lambda row: row['warning'] / float(row['experiment1']), axis = 1)\n",
    "    data[p]['danger'] = data[p].apply(lambda row: row['danger'] / float(row['experiment1']), axis = 1)\n",
    "    data[p]['suggestion'] = data[p].apply(lambda row: row['suggestion'] / float(row['experiment2']), axis = 1)\n",
    "    data[p]['hours'] = data[p].apply(lambda row: row['hours'] / float(row['experiment2']), axis = 1)\n",
    "    data[p]['numerical'] = data[p].apply(lambda row: row['numerical'] / float(row['experiment2']), axis = 1)\n",
    "    data[p] = data[p].T\n",
    "    #print data[p]\n",
    "\n",
    "\n",
    "\n",
    "# financial responsibility\n",
    "data['responsibility'] = data['judgments'].copy()\n",
    "data['responsibility'] = data['responsibility'][['output.experiment1','output.experiment2','output.indebt','output.regret','output.s_none','output.s_warning','output.s_danger','output.s_suggestion','output.s_hours','output.s_numerical']]\n",
    "data['responsibility'].columns = ['experiment1','experiment2','affordcheck','payontime','none','warning','danger','suggestion','hours','numerical']\n",
    "\n",
    "data['responsibility']['affordcheck'] = data['responsibility']['affordcheck'].apply(lambda x: 1 if x == 'eens' else 0)\n",
    "data['responsibility']['payontime'] = data['responsibility']['payontime'].apply(lambda x: 1 if x == 'eens' else 0)\n",
    "data['responsibility']['responsibility'] = data['responsibility']['affordcheck'] + data['responsibility']['payontime']\n",
    "\n",
    "data['responsibility']['none'] = data['responsibility']['none'].apply(lambda x: 1 if x == 'submit' else 0)\n",
    "data['responsibility']['warning'] = data['responsibility']['warning'].apply(lambda x: 1 if x == 'submit' else 0)\n",
    "data['responsibility']['danger'] = data['responsibility']['danger'].apply(lambda x: 1 if x == 'submit' else 0)\n",
    "data['responsibility']['suggestion'] = data['responsibility']['suggestion'].apply(lambda x: 1 if x == 'submit' else 0)\n",
    "data['responsibility']['hours'] = data['responsibility']['hours'].apply(lambda x: 1 if x == 'submit' else 0)\n",
    "data['responsibility']['numerical'] = data['responsibility']['numerical'].apply(lambda x: 1 if x == 'submit' else 0)\n",
    "\n",
    "agg = {\n",
    "    'experiment1' : 'sum',\n",
    "    'experiment2' : 'sum',\n",
    "    'none' : 'sum',\n",
    "    'warning' : 'sum',\n",
    "    'danger' : 'sum',\n",
    "    'suggestion' : 'sum',\n",
    "    'hours' : 'sum',\n",
    "    'numerical' : 'sum',\n",
    "}\n",
    "\n",
    "data['responsibility'] = data['responsibility'].groupby(['responsibility']).agg(agg)\n",
    "data['responsibility']['none'] = data['responsibility'].apply(lambda row: row['none'] / float(row['experiment1']), axis = 1)\n",
    "data['responsibility']['warning'] = data['responsibility'].apply(lambda row: row['warning'] / float(row['experiment1']), axis = 1)\n",
    "data['responsibility']['danger'] = data['responsibility'].apply(lambda row: row['danger'] / float(row['experiment1']), axis = 1)\n",
    "data['responsibility']['suggestion'] = data['responsibility'].apply(lambda row: row['suggestion'] / float(row['experiment2']), axis = 1)\n",
    "data['responsibility']['hours'] = data['responsibility'].apply(lambda row: row['hours'] / float(row['experiment2']), axis = 1)\n",
    "data['responsibility']['numerical'] = data['responsibility'].apply(lambda row: row['numerical'] / float(row['experiment2']), axis = 1)\n",
    "data['responsibility'] = data['responsibility'].T\n",
    "#print data['responsibility']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#\n",
    "# aggregate by time exposure\n",
    "#\n",
    "data['scenarios'] = data['judgments'][['output.s_none','output.s_warning','output.s_danger','output.s_suggestion','output.s_hours','output.s_numerical']].apply(pd.Series.value_counts).T\n",
    "data['scenarios'].index = ['none','warning','danger','suggestion','hours','numerical']\n",
    "\n",
    "rows = data['judgments'].index.size\n",
    "#data['scenarios']['cancel_ratio'] = data['scenarios']['cancel'].apply(lambda x: float(x) / rows)\n",
    "#data['scenarios']['submit_ratio'] = 0\n",
    "data['scenarios']['submit_ratio'] = data['scenarios'].apply(lambda row: row['submit'] / (float(row['cancel']) + float(row['submit'])), axis=1)\n",
    "#print data['scenarios']\n",
    "\n",
    "data['scenarios']['duration_avg'] = 0\n",
    "data['scenarios'].loc['none','duration_avg'] = np.asarray(data['judgments']['output.time_none'], dtype=np.float).mean()\n",
    "data['scenarios'].loc['warning','duration_avg'] = np.asarray(data['judgments']['output.time_warning'], dtype=np.float).mean()\n",
    "data['scenarios'].loc['danger','duration_avg'] = np.asarray(data['judgments']['output.time_danger'], dtype=np.float).mean()\n",
    "data['scenarios'].loc['suggestion','duration_avg'] = np.asarray(data['judgments']['output.time_suggestion'], dtype=np.float).mean()\n",
    "data['scenarios'].loc['hours','duration_avg'] = np.asarray(data['judgments']['output.time_hours'], dtype=np.float).mean()\n",
    "data['scenarios'].loc['numerical','duration_avg'] = np.asarray(data['judgments']['output.time_numerical'], dtype=np.float).mean()\n",
    "\n",
    "\n",
    "# scenarios\n",
    "data['scenarios'] = data['judgments'].copy()\n",
    "data['scenarios'] = data['scenarios'][['output.experiment1','output.experiment2','output.s_none','output.s_warning','output.s_danger','output.s_suggestion','output.s_hours','output.s_numerical']]\n",
    "data['scenarios'].columns = ['experiment1','experiment2','none','warning','danger','suggestion','hours','numerical']\n",
    "\n",
    "data['scenarios']['none'] = data['scenarios']['none'].apply(lambda x: 1 if x == 'submit' else 0)\n",
    "data['scenarios']['warning'] = data['scenarios']['warning'].apply(lambda x: 1 if x == 'submit' else 0)\n",
    "data['scenarios']['danger'] = data['scenarios']['danger'].apply(lambda x: 1 if x == 'submit' else 0)\n",
    "data['scenarios']['suggestion'] = data['scenarios']['suggestion'].apply(lambda x: 1 if x == 'submit' else 0)\n",
    "data['scenarios']['hours'] = data['scenarios']['hours'].apply(lambda x: 1 if x == 'submit' else 0)\n",
    "data['scenarios']['numerical'] = data['scenarios']['numerical'].apply(lambda x: 1 if x == 'submit' else 0)\n",
    "\n",
    "# t.tests\n",
    "import scipy.stats\n",
    "exp1 = data['scenarios'][data['scenarios']['experiment1'] == 1]\n",
    "print 'none-warning t-test',scipy.stats.ttest_rel(exp1['none'],exp1['warning'])\n",
    "\n",
    "agg = {\n",
    "    'experiment1' : 'sum',\n",
    "    'experiment2' : 'sum',\n",
    "    'none' : 'sum',\n",
    "    'warning' : 'sum',\n",
    "    'danger' : 'sum',\n",
    "    'suggestion' : 'sum',\n",
    "    'hours' : 'sum',\n",
    "    'numerical' : 'sum',\n",
    "}\n",
    "\n",
    "data['scenarios'] = data['scenarios'].groupby(['experiment1']).agg(agg)\n",
    "data['scenarios']['none'] = data['scenarios'].apply(lambda row: row['none'] / float(row['experiment1']), axis = 1)\n",
    "data['scenarios']['warning'] = data['scenarios'].apply(lambda row: row['warning'] / float(row['experiment1']), axis = 1)\n",
    "data['scenarios']['danger'] = data['scenarios'].apply(lambda row: row['danger'] / float(row['experiment1']), axis = 1)\n",
    "data['scenarios']['suggestion'] = data['scenarios'].apply(lambda row: row['suggestion'] / float(row['experiment2']), axis = 1)\n",
    "data['scenarios']['hours'] = data['scenarios'].apply(lambda row: row['hours'] / float(row['experiment2']), axis = 1)\n",
    "data['scenarios']['numerical'] = data['scenarios'].apply(lambda row: row['numerical'] / float(row['experiment2']), axis = 1)\n",
    "#data['scenarios'] = data['scenarios'].T\n",
    "#print data['scenarios'].head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "anova = data['judgments'].copy()\n",
    "anova[['output.s_none','output.s_warning','output.s_danger']] = anova[['output.s_none','output.s_warning','output.s_danger']].apply(lambda x: x.replace('cancel',1))\n",
    "anova[['output.s_none','output.s_warning','output.s_danger']] = anova[['output.s_none','output.s_warning','output.s_danger']].apply(lambda x: x.replace('submit',0))\n",
    "F, p = stats.f_oneway(anova['output.s_none'], anova['output.s_warning'], anova['output.s_danger'])\n",
    "print F,p\n",
    "\n",
    "anova = data['judgments'].copy()\n",
    "anova[['output.s_suggestion','output.s_hours','output.s_numerical']] = anova[['output.s_suggestion','output.s_hours','output.s_numerical']].apply(lambda x: x.replace('cancel',1))\n",
    "anova[['output.s_suggestion','output.s_hours','output.s_numerical']] = anova[['output.s_suggestion','output.s_hours','output.s_numerical']].apply(lambda x: x.replace('submit',0))\n",
    "F, p = stats.f_oneway(anova['output.s_suggestion'], anova['output.s_hours'], anova['output.s_numerical'])\n",
    "print F,p\n",
    "\n",
    "\n",
    "\n",
    "# feelings\n",
    "def pos(feelings):\n",
    "    for f in feelings.split(','):\n",
    "        if f in ['tevreden','blij','opgewonden','opgelucht']:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def neg(feelings):\n",
    "    for f in feelings.split(','):\n",
    "        if f in ['bezorgd','schuldig','verdrietig','boos','beschaamd','ontevreden']:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def neutral(feelings):\n",
    "    for f in feelings.split(','):\n",
    "        if f in ['weetniet']:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "    \n",
    "feelings = data['judgments'].copy()\n",
    "feelings = feelings[['output.s_none','output.s_warning','output.s_danger','output.feeling_none','output.feeling_warning','output.feeling_danger','output.s_suggestion','output.s_hours','output.s_numerical','output.feeling_suggestion','output.feeling_hours','output.feeling_numerical']]\n",
    "\n",
    "feelings['s_none_pos'] = feelings['output.feeling_none'].apply(lambda x: pos(x))\n",
    "feelings['s_none_neg'] = feelings['output.feeling_none'].apply(lambda x: neg(x))\n",
    "feelings['s_none_neutral'] = feelings['output.feeling_none'].apply(lambda x: neutral(x))\n",
    "feelings['s_warning_pos'] = feelings['output.feeling_warning'].apply(lambda x: pos(x))\n",
    "feelings['s_warning_neg'] = feelings['output.feeling_warning'].apply(lambda x: neg(x))\n",
    "feelings['s_warning_neutral'] = feelings['output.feeling_warning'].apply(lambda x: neutral(x))\n",
    "feelings['s_danger_pos'] = feelings['output.feeling_danger'].apply(lambda x: pos(x))\n",
    "feelings['s_danger_neg'] = feelings['output.feeling_danger'].apply(lambda x: neg(x))\n",
    "feelings['s_danger_neutral'] = feelings['output.feeling_danger'].apply(lambda x: neutral(x))\n",
    "\n",
    "feelings['s_suggestion_pos'] = feelings['output.feeling_suggestion'].apply(lambda x: pos(x))\n",
    "feelings['s_suggestion_neg'] = feelings['output.feeling_suggestion'].apply(lambda x: neg(x))\n",
    "feelings['s_suggestion_neutral'] = feelings['output.feeling_suggestion'].apply(lambda x: neutral(x))\n",
    "feelings['s_hours_pos'] = feelings['output.feeling_hours'].apply(lambda x: pos(x))\n",
    "feelings['s_hours_neg'] = feelings['output.feeling_hours'].apply(lambda x: neg(x))\n",
    "feelings['s_hours_neutral'] = feelings['output.feeling_hours'].apply(lambda x: neutral(x))\n",
    "feelings['s_numerical_pos'] = feelings['output.feeling_numerical'].apply(lambda x: pos(x))\n",
    "feelings['s_numerical_neg'] = feelings['output.feeling_numerical'].apply(lambda x: neg(x))\n",
    "feelings['s_numerical_neutral'] = feelings['output.feeling_numerical'].apply(lambda x: neutral(x))\n",
    "\n",
    "#print feelings.head()\n",
    "data['feelings'] = feelings\n",
    "\n",
    "data['feeling_count'] = pd.DataFrame()\n",
    "data['feeling_count']['none'] = pd.DataFrame([i for f in data['judgments']['output.feeling_none'].tolist() for i in f.split(',')]).loc[:,0].value_counts()\n",
    "data['feeling_count']['warning'] = pd.DataFrame([i for f in data['judgments']['output.feeling_warning'].tolist() for i in f.split(',')]).loc[:,0].value_counts()\n",
    "data['feeling_count']['danger'] = pd.DataFrame([i for f in data['judgments']['output.feeling_danger'].tolist() for i in f.split(',')]).loc[:,0].value_counts()\n",
    "data['feeling_count']['suggestion'] = pd.DataFrame([i for f in data['judgments']['output.feeling_suggestion'].tolist() for i in f.split(',')]).loc[:,0].value_counts()\n",
    "data['feeling_count']['hours'] = pd.DataFrame([i for f in data['judgments']['output.feeling_hours'].tolist() for i in f.split(',')]).loc[:,0].value_counts()\n",
    "data['feeling_count']['numerical'] = pd.DataFrame([i for f in data['judgments']['output.feeling_numerical'].tolist() for i in f.split(',')]).loc[:,0].value_counts()\n",
    "\n",
    "#data['feeling_count']['none'] = .value_counts()\n",
    "#data['feeling_count']['warning'] = data['judgments']['output.feeling_warning'].value_counts()\n",
    "print data['feeling_count']\n",
    "\n",
    "crowdtruth.save(data, config, folder+'/Data/3.aggregated/')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
